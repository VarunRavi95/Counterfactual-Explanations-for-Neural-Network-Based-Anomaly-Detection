{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data from SKAB Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VSIE43\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from scipy.stats import gaussian_kde\n",
    "import plotly.figure_factory as ff\n",
    "# from utility_functions import *\n",
    "# from models import *\n",
    "from scipy.spatial import distance\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # This is needed for 3D plotting\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "import random\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(42)\n",
    "# np.random.seed(42)\n",
    "# torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=42\n",
    "random.seed(s)\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = r'C:\\Users\\VSIE43\\OneDrive - Scania CV\\SKAB-master\\data/'\n",
    "normal_file = 'anomaly-free/anomaly-free.csv'\n",
    "test_1 = 'other'\n",
    "test_2 = 'valve1'\n",
    "test_3 = 'valve2'\n",
    "\n",
    "df = pd.read_csv(data_pth+normal_file, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillin_time_gaps(df):\n",
    "    df.datetime = pd.to_datetime(df.datetime.values)\n",
    "    time_diff = np.diff(df.datetime.values)\n",
    "\n",
    "    # there will be need for data imputation. \n",
    "    # some samples are with differnce of 2 seconds, rather than 1 second\n",
    "    new_time = pd.date_range(df.datetime.min(), df.datetime.max(),freq='1s')\n",
    "    missing_time = pd.DataFrame({'datetime' : new_time})\n",
    "    df_new = missing_time.merge(df, on='datetime', how='left')\n",
    "\n",
    "    # maybe fill in with interpolation\n",
    "    df_new = df_new.interpolate(method='ffill')\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = []\n",
    "df = pd.read_csv(data_pth+normal_file, sep=';')\n",
    "normal_data.append(fillin_time_gaps(df).drop(columns=['datetime']))\n",
    "for folder in [test_2, test_3]:\n",
    "    files = os.listdir(data_pth+folder)\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        tmp = pd.read_csv(data_pth+folder+'/'+file, sep=';')\n",
    "        # print(tmp.columns)\n",
    "        # t = tmp[tmp.anomaly==1]\n",
    "        t=tmp[tmp.anomaly==0]\n",
    "        t = t.drop(columns=['datetime','anomaly','changepoint'])\n",
    "        normal_data.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fillin_time_gaps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(df, m_m_params=None):\n",
    "    if m_m_params:\n",
    "        (min_p, max_p) = m_m_params\n",
    "    else:\n",
    "        (min_p, max_p) = df.min(), df.max()\n",
    "\n",
    "    new_df = (df-min_p) / (max_p-min_p)\n",
    "\n",
    "    return new_df,  (min_p, max_p)\n",
    "\n",
    "\n",
    "# data, m_m_params = min_max_normalize(df.drop(columns=['datetime']))\n",
    "# ind = math.floor(0.8*len(data))\n",
    "# train_data = data[:ind]\n",
    "# val_data = data[ind:]\n",
    "# # del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_window(X, look_back=64):\n",
    "    dataX = []\n",
    "    for i in range(len(X)-look_back-1):\n",
    "        a = X[i:(i+look_back), :]\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "# train_x = create_time_window(train_data.values)\n",
    "# val_x = create_time_window(val_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data from more data\n",
    "\n",
    "train_ext_x  = []\n",
    "val_ext_x = []\n",
    "tmp = []\n",
    "[tmp.append(create_time_window(t.values)) for t in normal_data]\n",
    "for t in tmp:\n",
    "    ind = math.floor(0.8*len(t))\n",
    "    val_ext_x.append(t[ind:])\n",
    "    train_ext_x.append(t[:ind])\n",
    "\n",
    "# [print(tmp.shape) for tmp in train_ext_x]\n",
    "train_ext_x = np.concatenate(train_ext_x, axis=0)\n",
    "new_m_m_parms =  train_ext_x.min(axis=(0,1)), train_ext_x.max(axis=(0,1))\n",
    "train_ext_x,_ = min_max_normalize(train_ext_x, new_m_m_parms)\n",
    "\n",
    "val_ext_x = np.concatenate(val_ext_x, axis=0)\n",
    "val_ext_x,_ = min_max_normalize(val_ext_x, new_m_m_parms)\n",
    "\n",
    "\n",
    "# l_ind = len(train_ext_x)-math.floor(len(train_ext_x)*.8)\n",
    "# rand_index = np.random.randint(0,len(train_ext_x),l_ind)\n",
    "\n",
    "# val_ext_x = train_ext_x[rand_index]\n",
    "# train_ext_x = np.delete(train_ext_x,rand_index)\n",
    "# val_ext_x = train_ext_x[ind:]\n",
    "# train_ext_x = train_ext_x[:ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ext_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ext_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_dataloader(data, batch_size, shuffle):\n",
    "\n",
    "    data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "    print(data_tensor.transpose(1,2).shape)\n",
    "    dataset_ae = TensorDataset(data_tensor.transpose(1,2), data_tensor.transpose(1,2))\n",
    "    dataloader_ae = DataLoader(dataset_ae, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return dataloader_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = array_to_dataloader(train_ext_x, batch_size=32, shuffle=False)\n",
    "val_dataloader = array_to_dataloader(val_ext_x, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "    num_columns = len(data.columns)\n",
    "    nrows = num_columns  # One row for each column\n",
    "\n",
    "    # Decrease the height allocated to each subplot by reducing the second element of the figsize tuple.\n",
    "    # Adjust the 5 in figsize=(10, 5) based on your preference and the actual number of subplots.\n",
    "    height_per_subplot = 1  # Adjust this value to change the height per subplot\n",
    "    fig = plt.figure(figsize=(10, height_per_subplot * nrows))\n",
    "    \n",
    "    # Create subplots with adjusted spacing using 'subplots_adjust' if necessary.\n",
    "    # The 'hspace' parameter controls the height of the padding between subplots.\n",
    "    gs = fig.add_gridspec(nrows, 1, hspace=0.35)  # Adjust hspace as needed\n",
    "    \n",
    "    for i, column in enumerate(data.columns):\n",
    "        ax = fig.add_subplot(gs[i, 0])\n",
    "\n",
    "        # Plot the line on the ith subplot\n",
    "        ax.plot(data[column], label=f'Signal_{i+1}')\n",
    "        \n",
    "        # Set y-axis to show only the min and max values\n",
    "        col_min = data[column].min()\n",
    "        col_max = data[column].max()\n",
    "        ax.set_ylim(col_min, col_max)\n",
    "        ax.set_yticks([col_min, col_max])  # Show only ticks for min and max\n",
    "        \n",
    "        # Format the y-tick labels\n",
    "        ax.yaxis.set_major_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "        \n",
    "        # Set title aligned to the left\n",
    "        ax.set_title(f'Signal_{i+1}', loc='left', fontsize=10, verticalalignment='center')\n",
    "        \n",
    "        # Show legend with column name\n",
    "        # ax.legend(loc='upper right')\n",
    "\n",
    "        # Make x-axis ticks visible only for the last subplot\n",
    "        if i < num_columns - 1:\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "\n",
    "    # Adjust the layout to prevent overlap and save the figure\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('compact_subplots.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_1 = pd.read_csv(data_pth+test_1+'/1.csv',sep=';')\n",
    "test_df_1_norm, _  = min_max_normalize(test_df_1.drop(columns=['datetime','anomaly','changepoint']),new_m_m_parms)\n",
    "test_x = create_time_window(test_df_1_norm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(test_df_1_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = array_to_dataloader(test_x, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection - Conv1D Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DVAE(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Conv1DVAE, self).__init__()\n",
    "\n",
    "        self.total_features = num_features\n",
    "        # Adjusted for num_features and seq_length\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.total_features, out_channels=32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Adjusted h_dim based on the output size of the last Conv1d layer, which may need fine-tuning\n",
    "        self.fc1 = nn.Linear(64, 64)  # Adjust for a more gradual reduction\n",
    "        self.fc2 = nn.Linear(64, 32)  # Further reduce dimensionality\n",
    "        self.fc3 = nn.Linear(32, 16)  # mu layer, increased from 8 to 16\n",
    "        self.fc4 = nn.Linear(32, 16)  # logvar layer, increased from 8 to 16\n",
    "        self.fc5 = nn.Linear(16, 32)  # For decoding, start expansion\n",
    "        self.fc6 = nn.Linear(32, 64)  # Continue expansion\n",
    "        self.fc7 = nn.Linear(64, 64)  # Prepare for decoder convolution layers\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=64, out_channels=32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=32, out_channels=self.total_features, kernel_size=5, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "    # def encode(self, x, k=10): # x ->(1, 64, 10) x_hat->(k, 64, 10)\n",
    "    #  return z , mu, log_var # z ->(k, 64, l)\n",
    "        \n",
    "\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        h = self.fc1(x)\n",
    "        h = self.fc2(h)\n",
    "\n",
    "        mu = self.fc3(h)\n",
    "        \n",
    "        logvar = self.fc4(h)\n",
    "\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        \n",
    "        z = self.fc5(z)  # Prepare z for the decoder\n",
    "        z = self.fc6(z)\n",
    "        z = self.fc7(z)\n",
    "\n",
    "        x_recon = self.decoder(z)\n",
    "        \n",
    "        x_recon = x_recon.transpose(1,2)\n",
    "       \n",
    "        return x_recon\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        x_recon = self.decode(z)\n",
    "        # Return the reconstructed outputs, along with the latent variables for loss calculation\n",
    "        return x_recon.transpose(1,2), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DVAE(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Conv1DVAE, self).__init__()\n",
    "        self.total_features = num_features\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.total_features, out_channels=32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Fully connected layers for mu and logvar\n",
    "        self.fc1 = nn.Linear(64, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)  # mu layer\n",
    "        self.fc4 = nn.Linear(32, 16)  # logvar layer\n",
    "\n",
    "        # Decoder FC layers\n",
    "        self.fc5 = nn.Linear(16, 32)\n",
    "        self.fc6 = nn.Linear(32, 64)\n",
    "        self.fc7 = nn.Linear(64, 64)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=64, out_channels=32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=32, out_channels=self.total_features, kernel_size=5, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + (eps * std)\n",
    "\n",
    "    def encode(self, x, k=10):\n",
    "        batch_size, _, seq_length = x.size()\n",
    "        mu_list = []\n",
    "        logvar_list = []\n",
    "        z_list = []\n",
    "\n",
    "        for i in range(k):\n",
    "            x_encoded = self.encoder(x)\n",
    "            h = self.fc1(x_encoded)\n",
    "            h = self.fc2(h)\n",
    "            mu = self.fc3(h)\n",
    "            logvar = self.fc4(h)\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            mu_list.append(mu)\n",
    "            logvar_list.append(logvar)\n",
    "            z_list.append(z)\n",
    "\n",
    "        # Stack on new dimension to return tensors of shape [batch_size, num_features, seq_length, k]\n",
    "        mu_stack = torch.stack(mu_list, dim=3)\n",
    "        logvar_stack = torch.stack(logvar_list, dim=3)\n",
    "        z_stack = torch.stack(z_list, dim=3)\n",
    "        return z_stack, mu_stack, logvar_stack\n",
    "\n",
    "    def decode(self, z):\n",
    "        # Assuming z shape [batch_size, num_features, seq_length, k]\n",
    "        batch_size, num_features, seq_length, k = z.size()\n",
    "        x_recon_list = []\n",
    "\n",
    "        for i in range(k):\n",
    "            sample = z[:, :, :, i]  # Get the ith sample across all batches\n",
    "            z_processed = self.fc5(sample)\n",
    "            z_processed = self.fc6(z_processed)\n",
    "            z_processed = self.fc7(z_processed)\n",
    "            x_recon = self.decoder(z_processed)\n",
    "            x_recon_list.append(x_recon)\n",
    "\n",
    "        # Stack the reconstructions along the last dimension to match the desired output shape\n",
    "        x_recon_stack = torch.stack(x_recon_list, dim=3)\n",
    "        return x_recon_stack\n",
    "\n",
    "    def forward(self, x, k=10):\n",
    "        z, mu, logvar = self.encode(x, k)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_num_features = train_ext_x.shape[2]\n",
    "tot_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "vae_model = Conv1DVAE(num_features=tot_num_features)\n",
    "# vae_model = ConvVAE()\n",
    "vae_optimizer = optim.Adam(vae_model.parameters(), lr=0.0001, amsgrad=True)\n",
    "scheduler_vae = StepLR(vae_optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn(pred, target, mu, logvar):\n",
    "#     # BCE = F.binary_cross_entropy(bin_output, bin_target)\n",
    "#     mseLoss = nn.MSELoss()\n",
    "\n",
    "#     loss = mseLoss(pred, target)\n",
    "#     # see Appendix B from VAE paper:\n",
    "#     # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "#     # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "#     KLD =  -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "#     return loss + (0.1*KLD), loss, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred, target, mu, logvar, k):\n",
    "    mseLoss = nn.MSELoss()\n",
    "    \n",
    "    # Calculate MSE loss for each of the k samples and average them\n",
    "    loss = torch.mean(torch.stack([mseLoss(pred[..., i], target) for i in range(k)], dim=0))\n",
    "    \n",
    "    # Compute KLD for each of the k samples and average them\n",
    "    KLD = -0.5 * torch.mean(torch.mean(1 + logvar - mu.pow(2) - logvar.exp(), dim=[0, 1, 2, 3]))\n",
    "\n",
    "    return loss + (0.1 * KLD), loss, KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Assuming `vae_model` and `vae_optimizer` have been defined\n",
    "vae_model = vae_model.to(device)\n",
    "vae_optimizer = optim.Adam(vae_model.parameters(), lr=0.0001, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_losses, val_losses = [], []\n",
    "train_cont_losses, train_bin_losses = [], []\n",
    "val_cont_losses, val_bin_losses = [], []\n",
    "\n",
    "# Initialize the variable to track the lowest validation loss\n",
    "best_val_loss = float('inf')\n",
    "best_model_path_vae = 'C:/Users/VSIE43/OneDrive - Scania CV/Models/best_model_vae_skab_2May_new_seed'+str(s)+'.pth'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    vae_model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    for data, target in train_dataloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output, mu, logvar = vae_model(data)\n",
    "        loss_elbo, loss, kld = loss_fn(output, target, mu, logvar, k=10)\n",
    "\n",
    "        vae_optimizer.zero_grad()\n",
    "        loss_elbo.backward()\n",
    "        vae_optimizer.step()\n",
    "\n",
    "        train_loss += loss_elbo.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    vae_model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, mu, logvar = vae_model(data)\n",
    "            loss_elbo_val, loss, kld = loss_fn(output, target, mu, logvar, k=10)\n",
    "            val_loss += loss_elbo_val.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(vae_model.state_dict(), best_model_path_vae)\n",
    "        print(f\"Epoch {epoch+1}: New best model saved with loss {avg_val_loss:.4f}\")\n",
    "\n",
    "# Plotting training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path_vae = 'C:/Users/VSIE43/OneDrive - Scania CV/Models/best_model_vae_skab_2May_new_seed'+str(s)+'.pth'\n",
    "best_model_vae = vae_model  # Assuming 'model' is an instance of your model class\n",
    "best_model_vae.load_state_dict(torch.load(best_model_path_vae))\n",
    "print(\"Loaded the best model.\")\n",
    "print(best_model_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_original_sequences(dataloader):\n",
    "    original_sequences = []\n",
    "\n",
    "    # Iterate over both dataloaders simultaneously\n",
    "    for data, _ in dataloader:\n",
    "\n",
    "        original_sequences.append(data.cpu().numpy())\n",
    "\n",
    "    original_sequences = np.concatenate(original_sequences, axis=0)\n",
    "    \n",
    "    return original_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_sequences = reconstruct_original_sequences(train_dataloader)\n",
    "original_val_sequences = reconstruct_original_sequences(val_dataloader)\n",
    "original_test_sequences = reconstruct_original_sequences(test_dataloader)\n",
    "# original_test_sequences_rearWheel = reconstruct_original_sequences(anom_dataloader_rearWheel)\n",
    "print(\"Original Train Shape:\", original_train_sequences.shape)\n",
    "print(\"Original Validation  Shape:\", original_val_sequences.shape)\n",
    "print(\"Original Test Shape:\", original_test_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vae_model_predictions(model_vae, dataloader, original_sequences, window_index, feature_index):\n",
    "    model_vae.eval()  # Ensure the model is in evaluation mode\n",
    "    all_predicted_signals = []\n",
    "\n",
    "    with torch.no_grad():  # No gradient needed for evaluation\n",
    "        # Loop through all batches in the DataLoader\n",
    "        for data, target in dataloader:\n",
    "            # Predict using the model for each batch\n",
    "            pred,_,_ = model_vae(data)\n",
    "            # Concatenate predictions for each batch\n",
    "            all_predicted_signals.append(pred)\n",
    "        \n",
    "        # Concatenate all predictions across batches\n",
    "        all_predicted_signals = torch.cat(all_predicted_signals, dim=0)\n",
    "    all_predicted_signals = np.array(all_predicted_signals)\n",
    "    # Ensure the concatenated predictions match the original sequences' shape\n",
    "    print(f\"Predicted Signals Shape: {all_predicted_signals.shape}\")\n",
    "    print(f\"Original Sequences Shape: {original_sequences.shape}\")\n",
    "\n",
    "    # Plotting (adjust as necessary for your specific needs)\n",
    "    # Example: Plotting the first feature of the first sequence\n",
    "    # plt.figure(figsize=(15, 5))\n",
    "    # plt.plot(original_sequences[window_index, feature_index, :], label='Original Signal', marker='o')  # Adjust indexing as per your data shape\n",
    "    # plt.plot(all_predicted_signals[window_index, feature_index, :], label='Reconstructed Signal', marker='x')  # Adjust indexing as per your data shape\n",
    "    # # plt.ylim(0,1)\n",
    "    # plt.title('Original vs. Reconstructed Signals')\n",
    "    # plt.xlabel('Window Length')\n",
    "    # plt.ylabel('Feature Value')\n",
    "    # plt.savefig('vae_recon_plot.png', bbox_inches='tight', dpi=1000)\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    return all_predicted_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vae_model_predictions(model_vae, dataloader, device):\n",
    "    model_vae.eval()  # Ensure the model is in evaluation mode\n",
    "    all_predicted_signals = []\n",
    "\n",
    "    with torch.no_grad():  # No gradient needed for evaluation\n",
    "        for data, target in dataloader:\n",
    "            # Move data to the appropriate device\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Predict using the model for each batch\n",
    "            pred, _, _ = model_vae(data)\n",
    "            \n",
    "            # Append predictions (with the k dimension intact)\n",
    "            all_predicted_signals.append(pred)\n",
    "\n",
    "        # Concatenate all predictions across batches\n",
    "        all_predicted_signals = torch.cat(all_predicted_signals, dim=0)\n",
    "        print(f\"Predicted Signals Shape: {all_predicted_signals.shape}\")\n",
    "    return all_predicted_signals.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_recon_vae_signals = plot_vae_model_predictions(best_model_vae, train_dataloader, original_train_sequences, 1500, 5)\n",
    "# valid_recon_vae_signals = plot_vae_model_predictions(best_model_vae, val_dataloader, original_val_sequences, 1000, 5)\n",
    "# test_recon_vae_signals = plot_vae_model_predictions(best_model_vae, test_dataloader, original_test_sequences, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recon_vae_signals = plot_vae_model_predictions(best_model_vae, train_dataloader, device)\n",
    "# valid_recon_vae_signals = plot_vae_model_predictions(best_model_vae, val_dataloader, device)\n",
    "# test_recon_vae_signals = plot_vae_model_predictions(best_model_vae, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss_mae_mse_vae = (train_recon_vae_signals - original_train_sequences)**2 + np.abs(train_recon_vae_signals - original_train_sequences)\n",
    "# valid_loss_mae_mse_vae = (valid_recon_vae_signals - original_val_sequences)**2 + np.abs(valid_recon_vae_signals - original_val_sequences)\n",
    "# test_loss_mae_mse_vae = (test_recon_vae_signals - original_test_sequences)**2 + np.abs(test_recon_vae_signals - original_test_sequences)\n",
    "# # test_loss_mae_mse_ae_rearWheel = (test_recon_ae_signals_rearWheel[:,:20,:] - original_test_sequences_rearWheel[:,:20,:])**2 + np.abs(test_recon_ae_signals_rearWheel[:,:20,:] - original_test_sequences_rearWheel[:,:20,:])\n",
    "\n",
    "# print('Train_cont Window Losses:', train_loss_mae_mse_vae.shape)\n",
    "# print('Valid_cont Window Losses:', valid_loss_mae_mse_vae.shape)\n",
    "# print('Test_cont Window Losses:', test_loss_mae_mse_vae.shape)\n",
    "# # print('Test_cont Window Losses:', test_loss_mae_mse_ae_rearWheel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recon_vae_signals.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_residuals_for_each_k_sample(recon_signals, original_signals):\n",
    "    # Ensure recon_signals shape: [batch_size, num_features, seq_length, k]\n",
    "    # Original signals should be expanded to match the shape for broadcasting\n",
    "    original_signals_expanded = np.expand_dims(original_signals, axis=-1)\n",
    "    \n",
    "    # Initialize an array to hold combined losses for all k samples\n",
    "    combined_losses = np.zeros_like(recon_signals)\n",
    "\n",
    "    # Compute MSE and MAE for each sample, store results in combined_losses\n",
    "    for i in range(recon_signals.shape[3]):\n",
    "        mse = (recon_signals[:,:,:,i] - original_signals) ** 2\n",
    "        mae = np.abs(recon_signals[:,:,:,i] - original_signals)\n",
    "        combined_losses[:,:,:,i] = mse + mae\n",
    "\n",
    "    return combined_losses\n",
    "\n",
    "# Example Usage\n",
    "train_loss_mae_mse_vae = calculate_residuals_for_each_k_sample(train_recon_vae_signals, original_train_sequences)\n",
    "valid_loss_mae_mse_vae = calculate_residuals_for_each_k_sample(valid_recon_vae_signals, original_val_sequences)\n",
    "test_loss_mae_mse_vae = calculate_residuals_for_each_k_sample(test_recon_vae_signals, original_test_sequences)\n",
    "\n",
    "print('Train Loss:', train_loss_mae_mse_vae.shape)\n",
    "print('Valid Loss:', valid_loss_mae_mse_vae.shape)\n",
    "print('Test Loss:', test_loss_mae_mse_vae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sample_loss_vae = np.mean(train_loss_mae_mse_vae, axis=2).mean(axis = 1)\n",
    "# valid_sample_loss_vae = np.mean(valid_loss_mae_mse_vae, axis=2).mean(axis = 1)\n",
    "# test_sample_loss_vae = np.mean(test_loss_mae_mse_vae, axis=2).mean(axis = 1)\n",
    "\n",
    "# print('Train_cont Sample Losses:', train_sample_loss_vae.shape)\n",
    "# print('Valid_cont Sample Losses:', valid_sample_loss_vae.shape)\n",
    "# print('Test_cont Sample Losses:', test_sample_loss_vae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_loss_vae = np.mean(train_loss_mae_mse_vae, axis=2).mean(axis = 1)\n",
    "valid_sample_loss_vae = np.mean(valid_loss_mae_mse_vae, axis=2).mean(axis = 1)\n",
    "test_sample_loss_vae = np.mean(test_loss_mae_mse_vae, axis=2).mean(axis = 1)\n",
    "\n",
    "print('Train_cont Sample Losses:', train_sample_loss_vae.shape)\n",
    "print('Valid_cont Sample Losses:', valid_sample_loss_vae.shape)\n",
    "print('Test_cont Sample Losses:', test_sample_loss_vae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_sample_losses(losses, title):\n",
    "    \"\"\"Plots boxplots for each k sample's losses.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Sample Index (k)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "# Plotting the sample losses for training, validation, and testing sets\n",
    "plot_sample_losses(train_sample_loss_vae, 'Training Sample Losses Distribution')\n",
    "plot_sample_losses(valid_sample_loss_vae, 'Validation Sample Losses Distribution')\n",
    "plot_sample_losses(test_sample_loss_vae, 'Test Sample Losses Distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_loss_vae = np.mean(train_loss_mae_mse_vae, axis=2)\n",
    "valid_feature_loss_vae = np.mean(valid_loss_mae_mse_vae, axis=2)\n",
    "test_feature_loss_vae = np.mean(test_loss_mae_mse_vae, axis=2)\n",
    "\n",
    "print('Train_cont Feature Losses:', train_feature_loss_vae.shape)\n",
    "print('Valid_cont Feature Losses:', valid_feature_loss_vae.shape)\n",
    "print('Test_cont Feature Losses:', test_feature_loss_vae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(valid_sample_loss_vae, 25)\n",
    "Q3 = np.percentile(valid_sample_loss_vae, 75)\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Determine the threshold as Q3 + multiplier * IQR\n",
    "threshold_vae = Q3 + 1.5 * IQR\n",
    "threshold_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_vae = np.percentile(valid_sample_loss_vae, 97.5)\n",
    "threshold_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold_vae = np.percentile(valid_sample_loss_vae, 95)\n",
    "# sns.histplot(train_losses, kde=True, color='red', alpha=0.2, edgecolor='black')\n",
    "fig = sns.histplot(valid_sample_loss_vae, kde=True, color='blue', alpha=0.3, edgecolor='black')\n",
    "fig.axvline(x = threshold_vae, linestyle = 'dashed', color = 'red')\n",
    "# sns.histplot(test_losses, kde=True, color='red', alpha=0.2, edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_sample_loss_vae)\n",
    "# plt.plot(test_df_1.anomaly)\n",
    "plt.figure()\n",
    "plt.plot(test_sample_loss_vae>0.6)\n",
    "plt.plot(test_df_1.anomaly.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # metrics\n",
    "\n",
    "def  f1_score(true, pred):\n",
    "    return metrics.f1_score(true, pred)\n",
    "\n",
    "def recall_score(true, pred):\n",
    "    return metrics.recall_score(true, pred)\n",
    "\n",
    "def auc_score(true, pred):\n",
    "    return metrics.roc_auc_score(true, pred)\n",
    "\n",
    "def fpr_score(true, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
    "    # print(c.shape)\n",
    "    # FP = c.sum(axis=0) - np.diag(c)  \n",
    "    # FN = c.sum(axis=1) - np.diag(c)\n",
    "    # TP = np.diag(c)\n",
    "    # TN = c.sum() - (FP + FN + TP)\n",
    "\n",
    "    return fp/(fp+tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# labels = []\n",
    "# file_number = []\n",
    "# # m = model_ext\n",
    "\n",
    "\n",
    "# files = os.listdir(data_pth+test_1)\n",
    "\n",
    "# print(files)\n",
    "# for file in files:\n",
    "#     tmp = pd.read_csv(data_pth+test_1+'/'+file, sep=';')\n",
    "#     t = tmp.anomaly.values\n",
    "#     test_df_1_norm, _  = min_max_normalize(tmp.drop(columns=['datetime','anomaly','changepoint']).values,new_m_m_parms)\n",
    "#     test_x = create_time_window(test_df_1_norm)\n",
    "#     test_dataloader = array_to_dataloader(test_x, batch_size=32, shuffle=False)\n",
    "#     original_test_sequences = reconstruct_original_sequences(test_dataloader)\n",
    "#     test_recon_ae_signals = plot_vae_model_predictions(best_model_vae, \n",
    "#                                                test_dataloader, \n",
    "#                                                original_test_sequences, \n",
    "#                                                window_index=600, \n",
    "#                                                feature_index=5)\n",
    "#     test_loss_mae_mse_ae = (test_recon_ae_signals - original_test_sequences)**2 + np.abs(test_recon_ae_signals - original_test_sequences)\n",
    "#     test_sample_loss_ae = np.mean(test_loss_mae_mse_ae, axis=2).mean(axis = 1)\n",
    "#     labels.append(t[-len(test_recon_ae_signals):])\n",
    "#     i = int(file.split('.')[0])\n",
    "#     file_number.append([i]*len(test_recon_ae_signals))\n",
    "#     preds.append(test_sample_loss_ae>threshold_vae)\n",
    "#     # i +=1\n",
    "    \n",
    "# preds = np.concatenate(preds, axis=0)\n",
    "# labels = np.concatenate(labels, axis=0)\n",
    "# file_number = np.concatenate(file_number, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# labels = []\n",
    "# file_number = []\n",
    "# # m = model_ext\n",
    "\n",
    "\n",
    "# files = os.listdir(data_pth+test_1)\n",
    "\n",
    "# print(files)\n",
    "# for file in files:\n",
    "#     tmp = pd.read_csv(data_pth+test_1+'/'+file, sep=';')\n",
    "#     t = tmp.anomaly.values\n",
    "#     test_df_1_norm, _  = min_max_normalize(tmp.drop(columns=['datetime','anomaly','changepoint']).values,new_m_m_parms)\n",
    "#     test_x = create_time_window(test_df_1_norm)\n",
    "#     test_dataloader = array_to_dataloader(test_x, batch_size=32, shuffle=False)\n",
    "#     original_test_sequences = reconstruct_original_sequences(test_dataloader)\n",
    "#     test_recon_ae_signals = plot_vae_model_predictions(best_model_vae, \n",
    "#                                                test_dataloader, \n",
    "#                                                device)\n",
    "#     test_loss_mae_mse_ae = calculate_residuals_for_each_k_sample(test_recon_ae_signals, original_test_sequences)\n",
    "#     test_sample_loss_ae = np.mean(test_loss_mae_mse_ae, axis=2).mean(axis = 1)\n",
    "#     labels.append(t[-len(test_recon_ae_signals):])\n",
    "#     i = int(file.split('.')[0])\n",
    "#     file_number.append([i]*len(test_recon_ae_signals))\n",
    "#     preds.append(test_sample_loss_ae>threshold_vae)\n",
    "#     # i +=1\n",
    "    \n",
    "# preds = np.concatenate(preds, axis=0)\n",
    "# labels = np.concatenate(labels, axis=0)\n",
    "# file_number = np.concatenate(file_number, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "file_number = []\n",
    "# m = model_ext\n",
    "\n",
    "\n",
    "files = os.listdir(data_pth+test_1)\n",
    "\n",
    "print(files)\n",
    "for file in files:\n",
    "    tmp = pd.read_csv(data_pth+test_1+'/'+file, sep=';')\n",
    "    t = tmp.anomaly.values\n",
    "    test_df_1_norm, _  = min_max_normalize(tmp.drop(columns=['datetime','anomaly','changepoint']).values,new_m_m_parms)\n",
    "    test_x = create_time_window(test_df_1_norm)\n",
    "    test_dataloader = array_to_dataloader(test_x, batch_size=32, shuffle=False)\n",
    "    original_test_sequences = reconstruct_original_sequences(test_dataloader)\n",
    "    test_recon_ae_signals = plot_vae_model_predictions(best_model_vae, \n",
    "                                               test_dataloader, \n",
    "                                               device)\n",
    "    test_loss_mae_mse_ae = calculate_residuals_for_each_k_sample(test_recon_ae_signals, original_test_sequences)\n",
    "    test_sample_loss_ae = np.mean(test_loss_mae_mse_ae, axis=2).mean(axis = 1)\n",
    "    labels.append(t[-len(test_recon_ae_signals):])\n",
    "    i = int(file.split('.')[0])\n",
    "    file_number.append([i]*len(test_recon_ae_signals))\n",
    "    preds.append(test_sample_loss_ae>threshold_vae)\n",
    "    # i +=1\n",
    "    \n",
    "preds = np.concatenate(preds, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "file_number = np.concatenate(file_number, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming fpr_score function is defined as before\n",
    "# def fpr_score(true, pred):\n",
    "#     tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
    "#     return fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "\n",
    "# # Metric functions list\n",
    "# metrics_functions = [f1_score, fpr_score, recall_score, auc_score]\n",
    "# metric_names = ['f1_score', 'fpr_score', 'recall_score', 'auc_score']\n",
    "\n",
    "# # Anomaly group ranges\n",
    "# anomaly_ranges = {\n",
    "#     'Fluid Leak Anomaly': range(1, 5),\n",
    "#     'Rotor Imbalance Anomaly': range(5, 10),\n",
    "#     'low/Sudden Increase in Water Anomaly': range(10, 12),\n",
    "#     'Cavitation Anomaly': range(12, 14),\n",
    "#     'High Temperature Anomaly': range(14, 15)\n",
    "# }\n",
    "\n",
    "# # Iterate over each metric function\n",
    "# for i, fun in enumerate(metrics_functions):\n",
    "#     print()\n",
    "#     print(metric_names[i])\n",
    "    \n",
    "#     # Iterate over each anomaly group\n",
    "#     for anomaly_name, indices in anomaly_ranges.items():\n",
    "#         scores = [fun(labels[file_number == f], preds[file_number == f]) for f in indices]\n",
    "#         average_score = np.mean(scores)\n",
    "#         print(f\"{anomaly_name} Average: {average_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_ranges = {\n",
    "    'Fluid Leak Anomaly': range(1, 5),\n",
    "    'Rotor Imbalance Anomaly': range(5, 10),\n",
    "    'Low/Sudden Increase in Water Anomaly': range(10, 12),\n",
    "    'Cavitation Anomaly': range(12, 14),\n",
    "    'High Temperature Anomaly': range(14, 15)\n",
    "}\n",
    "\n",
    "# Collect scores\n",
    "all_scores = {name: [] for name in anomaly_ranges.keys()}\n",
    "\n",
    "# Iterate over each anomaly group\n",
    "for anomaly_name, indices in anomaly_ranges.items():\n",
    "    # Collect scores for each k sample\n",
    "    scores_per_k = []\n",
    "    for k in range(preds.shape[1]):\n",
    "        scores = [f1_score(labels[file_number == f], preds[file_number == f, k]) for f in indices]\n",
    "        scores_per_k.append(scores)\n",
    "    all_scores[anomaly_name].append(scores_per_k)\n",
    "\n",
    "# Visualize scores\n",
    "for anomaly_name, scores in all_scores.items():\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i, k_scores in enumerate(scores):\n",
    "        plt.plot(k_scores, label=f'Sample {i}')\n",
    "    plt.title(f'F1 Scores for {anomaly_name}')\n",
    "    plt.xlabel('File Index')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp / (tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.in1d(file_number, list(range(5,15)))\n",
    "# print(np.unique(ind))\n",
    "recall_score(labels[ind],preds[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(labels,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fun in enumerate([f1_score, fpr_score, recall_score, auc_score]):\n",
    "    print()\n",
    "    print(['f1_score', 'fpr_score', 'recall_score', 'auc_score'][i])\n",
    "    for f in range(1,15):\n",
    "        print(fun(labels[file_number==f],preds[file_number==f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FPR - Fluid Leak: ', (0.09411+0.05882+0.07669+0.06185+0.08407)/5)\n",
    "print('FPR - Rotor Imbalance: ', (0.09411+0.05882+0.07669+0.06185+0.08407)/5)\n",
    "print('FPR - Rotor Imbalance: ', (0.09411+0.05882+0.07669+0.06185+0.08407)/5)\n",
    "print('FPR - Rotor Imbalance: ', (0.09411+0.05882+0.07669+0.06185+0.08407)/5)\n",
    "print('FPR - Rotor Imbalance: ', (0.09411+0.05882+0.07669+0.06185+0.08407)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_counterfactuals_adam_pytorch(dataloader, model, threshold=-np.inf, learning_rate=0.01, num_iterations=1000, exclude_signals=[]):\n",
    "    model.eval()\n",
    "    \n",
    "    all_counterfactuals = []\n",
    "    loss_lst = []\n",
    "    all_losses = []  # List to store losses for each batch\n",
    "\n",
    "    for batch_idx, (data, targe) in enumerate(dataloader):\n",
    "        # Ensure data is on the correct device and enable gradient\n",
    "        data = data.clone().detach().requires_grad_(True)\n",
    "        \n",
    "\n",
    "        # Create optimizers for both continuous and binary data\n",
    "        optimizer_data = torch.optim.Adam([data], lr=learning_rate)\n",
    "        batch_losses = []\n",
    "        for i in range(num_iterations):\n",
    "            optimizer_data.zero_grad()\n",
    "\n",
    "\n",
    "            output, mu, logvar = model(data)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss_cont = torch.mean(F.mse_loss(output, data, reduction='mean') + -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp()))\n",
    "            if loss_cont.item() < threshold:\n",
    "                break\n",
    "\n",
    "            loss_cont.backward()\n",
    "            batch_losses.append(loss_cont.item())\n",
    "\n",
    "            # Exclude specific signals from the gradient update\n",
    "            if exclude_signals:\n",
    "                with torch.no_grad():\n",
    "                    for exclude_signal in exclude_signals:\n",
    "                        data.grad[:, exclude_signal, :] = 0\n",
    "                        \n",
    "\n",
    "            optimizer_data.step()\n",
    "            \n",
    "\n",
    "        all_counterfactuals.append(data.detach().cpu().numpy())\n",
    "        all_losses.append(batch_losses)\n",
    "\n",
    "        # Optional: Plot loss per batch or just keep track of it\n",
    "        plt.plot(loss_lst)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'Loss over Iterations for Batch {batch_idx}')\n",
    "        plt.show()\n",
    "        # loss_lst = []  # Reset loss list for the next batch\n",
    "\n",
    "    # Combine all batches into a single numpy array\n",
    "    all_counterfactuals = np.concatenate(all_counterfactuals, axis=0)\n",
    "    \n",
    "\n",
    "    return all_counterfactuals, all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_indices = list(range(tot_num_features))\n",
    "validity_datasets = []\n",
    "sparsity_datasets = []\n",
    "proximity_datasets = []\n",
    "for i in range(5,6):\n",
    "    print()\n",
    "    print('File number: ', i)\n",
    "    test_df_1 = pd.read_csv(data_pth+test_1+'/'+str(i)+'.csv',sep=';')\n",
    "    test_df_1_norm, _  = min_max_normalize(test_df_1.drop(columns=['datetime','anomaly','changepoint']).values,new_m_m_parms)\n",
    "    test_x = create_time_window(test_df_1_norm)\n",
    "    test_dataloader = array_to_dataloader(test_x, batch_size=32, shuffle=False)\n",
    "    original_test_sequences = reconstruct_original_sequences(test_dataloader)\n",
    "    test_recon_ae_signals = plot_vae_model_predictions(best_model_vae, \n",
    "                                               test_dataloader, \n",
    "                                               original_test_sequences, \n",
    "                                               window_index=600, \n",
    "                                               feature_index=5)\n",
    "    test_loss_mae_mse_ae = (test_recon_ae_signals - original_test_sequences)**2 + np.abs(test_recon_ae_signals - original_test_sequences)\n",
    "    test_sample_loss_ae = np.mean(test_loss_mae_mse_ae, axis=2).mean(axis = 1)\n",
    "    test_feature_loss_ae = np.mean(test_loss_mae_mse_ae, axis=2)\n",
    "    # sns.heatmap(test_feature_loss_ae)\n",
    "    # sns.pairplot(test_df_1.drop(columns=['datetime','changepoint']), hue='anomaly')\n",
    "    # scaler = MinMaxScaler()\n",
    "    lof = LocalOutlierFactor(n_neighbors=2, contamination=0.4, algorithm='auto', metric='euclidean')\n",
    "    feature_losses_transposed = test_feature_loss_ae.T\n",
    "    # feature_losses_transposed_scaled = scaler.fit_transform(feature_losses_transposed)\n",
    "    anomalies = lof.fit_predict(feature_losses_transposed)\n",
    "\n",
    "    # Anomalies are marked with -1, so we can find them like this:\n",
    "    anomalous_feature_indices = np.where(anomalies == -1)[0]\n",
    "    \n",
    "    print(\"Anomalous Feature Indices:\", anomalous_feature_indices)\n",
    "\n",
    "    exclude_signals = [index for index in all_feature_indices if index not in anomalous_feature_indices]\n",
    "\n",
    "    print(\"Exclude Signals Mask:\", exclude_signals)\n",
    "    # plt.plot(test_sample_loss_ae)\n",
    "    # plt.figure()\n",
    "    # plt.plot(test_sample_loss_ae>ae_threshold)\n",
    "    # plt.plot(test_df_1.anomaly.values[-len(test_sample_loss_ae):])\n",
    "    # plt.show()\n",
    "    cf_anom, losses = create_counterfactuals_adam_pytorch(dataloader=test_dataloader, \n",
    "                                            model=best_model_vae, \n",
    "                                            num_iterations=350, \n",
    "                                            learning_rate=0.01,exclude_signals=exclude_signals)\n",
    "\n",
    "    cf_data_tensor = torch.tensor(cf_anom, dtype=torch.float32)\n",
    "    cf_dataset = TensorDataset(cf_data_tensor, cf_data_tensor)\n",
    "    cf_dataloader = DataLoader(cf_dataset, batch_size=32, shuffle=False)\n",
    "    original_cf_sequences = reconstruct_original_sequences(cf_dataloader)\n",
    "    recon_cf_signals = plot_vae_model_predictions(best_model_vae, \n",
    "                                            cf_dataloader,\n",
    "                                            original_cf_sequences,\n",
    "                                            195,\n",
    "                                            2)\n",
    "\n",
    "    cf_loss_mae_mse_ae = (recon_cf_signals - original_cf_sequences)**2 + np.abs(recon_cf_signals - original_cf_sequences)\n",
    "    cf_sample_loss_ae = np.mean(cf_loss_mae_mse_ae, axis=2).mean(axis = 1)\n",
    "\n",
    "    print('CF_cont Sample Losses:', cf_sample_loss_ae.shape)\n",
    "    valid_counterfactuals = np.mean(cf_sample_loss_ae < threshold_vae)\n",
    "    print(f'File Number {i} and its corresponding validity: {valid_counterfactuals}')\n",
    "    validity_datasets.append(valid_counterfactuals)\n",
    "    distances_per_timestep = np.sqrt(np.sum((original_test_sequences - cf_anom) ** 2, axis=2))\n",
    "\n",
    "    average_distances_per_sequence = np.mean(distances_per_timestep, axis=1)\n",
    "\n",
    "    overall_average_distance_per_window = np.mean(average_distances_per_sequence)\n",
    "    print(f'File Number {i} and its corresponding distance metric: {overall_average_distance_per_window}')\n",
    "    proximity_datasets.append(overall_average_distance_per_window)\n",
    "\n",
    "    change_threshold = 0.001\n",
    "\n",
    "    differences_exceed_threshold = np.abs(original_test_sequences - cf_anom) > change_threshold\n",
    "\n",
    "    sparsity_per_sequence = np.sum(differences_exceed_threshold, axis=(1, 2)) / (original_test_sequences.shape[1] * original_test_sequences.shape[2])\n",
    "\n",
    "    overall_average_sparsity = np.mean(sparsity_per_sequence)\n",
    "    print(f'File Number {i} and its corresponding sparsity metric: {overall_average_sparsity}')\n",
    "    sparsity_datasets.append(overall_average_sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomalous_classified_window(model, threshold, norm_parameter=new_m_m_parms, files=range(1,15), is_fp_tp=False):\n",
    "    data = []\n",
    "    file_number = []\n",
    "    fps = []\n",
    "    tps = []\n",
    "    for i in files:\n",
    "        print(i)\n",
    "        test_df_1 = pd.read_csv(data_pth+test_1+'/'+str(i)+'.csv',sep=';')\n",
    "        label= test_df_1['anomaly'][65:] \n",
    "        test_df_1_norm, _  = min_max_normalize(test_df_1.drop(columns=['datetime','anomaly','changepoint']).values,norm_parameter)\n",
    "        test_x = create_time_window(test_df_1_norm)\n",
    "        test_dataloader = array_to_dataloader(test_x, batch_size=32, shuffle=False)\n",
    "        original_test_sequences = reconstruct_original_sequences(test_dataloader)\n",
    "        test_recon_ae_signals = plot_vae_model_predictions(model, \n",
    "                                                test_dataloader, \n",
    "                                                original_test_sequences, \n",
    "                                                window_index=600, \n",
    "                                                feature_index=5)\n",
    "        test_loss_mae_mse_ae = (test_recon_ae_signals - original_test_sequences)**2 + np.abs(test_recon_ae_signals - original_test_sequences)\n",
    "        test_sample_loss_ae = np.mean(test_loss_mae_mse_ae, axis=2).mean(axis = 1)\n",
    "        t = test_sample_loss_ae>threshold\n",
    "        data.append(test_x[t])\n",
    "        file_number.append([i]*len(data[-1]))\n",
    "        fps.append(np.logical_and(label==0,t==1)[t==1])\n",
    "        tps.append(np.logical_and(label==1,t==1)[t==1])\n",
    "\n",
    "    if is_fp_tp:\n",
    "        return np.concatenate(data), np.concatenate(file_number), np.concatenate(fps), np.concatenate(tps)\n",
    "        \n",
    "    return np.concatenate(data), np.concatenate(file_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = range(5,15)#[5,6,7,9,13,14]\n",
    "data,file_num, ano_fps, ano_tps = get_anomalous_classified_window(best_model_vae,threshold_vae, files=files,is_fp_tp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# method 2 using feature wise threshold\n",
    "\n",
    "# testing option 1\n",
    "test_data = []\n",
    "labels_1 = []\n",
    "file_number = []\n",
    "# m = model_ext\n",
    "\n",
    "\n",
    "files = os.listdir(data_pth+test_1)\n",
    "\n",
    "print(files)\n",
    "for file in files:\n",
    "    tmp = pd.read_csv(data_pth+test_1+'/'+file, sep=';')\n",
    "    t = tmp.anomaly.values\n",
    "    test_df_1_norm, _  = min_max_normalize(tmp.drop(columns=['datetime','anomaly','changepoint']).values,new_m_m_parms)\n",
    "    test_x = create_time_window(test_df_1_norm)\n",
    "    # pred_x = model_ext.predict(test_x)\n",
    "    labels_1.append(t[-len(test_x):])\n",
    "    i = int(file.split('.')[0])\n",
    "    file_number.append([i]*len(test_x))\n",
    "    test_data.append(test_x)\n",
    "    # preds.append(anomaly_score_no_mean(np.squeeze(pred_x),np.squeeze(test_x)).mean(axis=1)>threshold)\n",
    "    # preds.append(np.any(anomaly_score_no_mean(np.squeeze(pred_x),np.squeeze(test_x)).mean(axis=1)>threshold_feature, axis=1))\n",
    "    # break\n",
    "    \n",
    "# preds = np.concatenate(preds, axis=0)\n",
    "test_data = np.concatenate(test_data)\n",
    "labels_1 = np.concatenate(labels_1, axis=0)\n",
    "file_number = np.concatenate(file_number, axis=0)\n",
    "\n",
    "\n",
    "dict_to_save = {'ano_data':data, 'cf_data':cf_anom, 'file_num':file_number }\n",
    "dict_to_save['test_data']=test_data\n",
    "dict_to_save['test_labels']=labels_1\n",
    "dict_to_save['test_file_num']=file_number\n",
    "\n",
    "dict_to_save['train_data']=train_ext_x\n",
    "\n",
    "import pickle as pk\n",
    "pk.dump(dict_to_save, open('skab_vae_grad.pk','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Path to the pickle file\n",
    "file_path_skab = 'skab_vae_grad.pk' \n",
    "\n",
    "# Attempt to open the file with error handling\n",
    "try:\n",
    "    with open(file_path_skab, 'rb') as file:\n",
    "        var_skab = pickle.load(file)\n",
    "    print(\"File loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path_skab}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_data_skab = var_skab['ano_data']\n",
    "ano_file_skab = var_skab['file_num']\n",
    "cf_data_skab = var_skab['cf_data']\n",
    "\n",
    "train_data_skab = var_skab['train_data']\n",
    "test_data_skab = var_skab['test_data']\n",
    "combined_file_num_skab = var_skab['test_file_num']\n",
    "\n",
    "index_counts_skab = Counter(combined_file_num_skab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_indices = index_counts_skab[1] + index_counts_skab[2] + index_counts_skab[3] + index_counts_skab[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_ind_test_data = test_data_skab[exclude_indices:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(var_skab['test_labels'][exclude_indices:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(var_skab['test_labels'][exclude_indices:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_combined_skab = np.array([0]*train_data_skab.shape[0]+ list(var_skab['test_labels'][exclude_indices:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap_projections(train_data, combined_test_data, anomaly_data, cf_data, labels_train_combined, plot_name):\n",
    "    \n",
    "    X_train_flat = train_data.reshape(train_data.shape[0], -1) if train_data.ndim > 2 else train_data\n",
    "    X_combined_flat = combined_test_data.reshape(combined_test_data.shape[0], -1) if combined_test_data.ndim > 2 else combined_test_data\n",
    "    X_anom_flat = anomaly_data.reshape(anomaly_data.shape[0], -1) if anomaly_data.ndim > 2 else anomaly_data\n",
    "    counterfactuals_flat = cf_data.reshape(cf_data.shape[0], -1) if cf_data.ndim > 2 else cf_data\n",
    "    \n",
    "    # Combine train and test data\n",
    "    X_train_combined = np.concatenate([X_train_flat, X_combined_flat], axis=0)\n",
    "    \n",
    "    # Initialize UMAP reducer\n",
    "    umap_reducer = umap.UMAP(n_neighbors=30, min_dist=0.5, n_components=2, metric='euclidean')\n",
    "    \n",
    "    # Transform data\n",
    "    X_reduced = umap_reducer.fit_transform(X_train_combined)\n",
    "    anomaly_reduced = umap_reducer.transform(X_anom_flat)\n",
    "    counterfactuals_reduced = umap_reducer.transform(counterfactuals_flat)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(X_reduced[labels_train_combined == 0, 0], X_reduced[labels_train_combined == 0, 1], label='Normal', alpha=0.5, color='limegreen')\n",
    "    plt.scatter(X_reduced[labels_train_combined == 1, 0], X_reduced[labels_train_combined == 1, 1], label='Anomaly', alpha=0.5, color='crimson')\n",
    "    # plt.scatter(anomaly_reduced[:, 0], anomaly_reduced[:, 1], label='Anomaly', alpha=0.5, color='crimson')\n",
    "    plt.scatter(counterfactuals_reduced[:, 0], counterfactuals_reduced[:, 1], label='Counterfactual', alpha=0.3, color='gold', edgecolor='k', marker='o', s=40)\n",
    "    plt.xlabel('UMAP Dimension 1', fontsize=20)\n",
    "    plt.ylabel('UMAP Dimension 2', fontsize=20)\n",
    "    plt.legend(loc='lower left', prop={'size': 15})\n",
    "    plt.savefig(f'umap_{plot_name}_grad_vae.png', dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap_projections(train_data=train_data_skab, \n",
    "                      combined_test_data=exclude_ind_test_data, \n",
    "                      anomaly_data=anomaly_data_skab, \n",
    "                      cf_data=cf_data_skab, \n",
    "                      labels_train_combined=labels_train_combined_skab, \n",
    "                      plot_name='skab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_names = ['Sensor_' + str(i) for i in range(test_loss_mae_mse_ae.shape[1])]\n",
    "plt.figure(figsize=(6, 6))\n",
    "heatmap = sns.heatmap(np.swapaxes(test_loss_mae_mse_ae,1,2)[400], xticklabels=sensor_names, cmap=\"viridis\")\n",
    "heatmap.set_title('Reconstruction Losses(Window Based) Heatmap')\n",
    "heatmap.set_xlabel('Number of Features/Sensors')\n",
    "heatmap.set_ylabel('Window length')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('recon_errors.png', bbox_inches='tight', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_from_tensor(tensor):\n",
    "    # Assuming tensor shape is (num_sequences, num_features, sequence_length)\n",
    "    # And the sequences are overlapping with step size of 1\n",
    "    \n",
    "    # Initialize an empty list to hold the reconstructed data\n",
    "    reconstructed_data = []\n",
    "    \n",
    "    # Convert tensor to numpy for easier manipulation if it's a torch tensor\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        tensor = tensor.numpy()\n",
    "    \n",
    "    num_sequences, num_features, sequence_length = tensor.shape\n",
    "    \n",
    "    # Iterate through the sequences\n",
    "    for i in range(num_sequences):\n",
    "        # For all but the last sequence, take the first element\n",
    "        if i < num_sequences - 1:\n",
    "            reconstructed_data.append(tensor[i, :, 0])\n",
    "        else:\n",
    "            # For the last sequence, take all elements to ensure we don't miss the tail of the dataset\n",
    "            reconstructed_data.extend(tensor[i, :, :].transpose())\n",
    "\n",
    "    # Convert the list to a numpy array\n",
    "    reconstructed_array = np.array(reconstructed_data)\n",
    "    \n",
    "    # Reshape the array back to 2D (num_samples, num_features)\n",
    "    # This step may not be necessary depending on how reconstructed_data is structured\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_reconstructed = pd.DataFrame(reconstructed_array, columns=sensor_names, dtype=np.float64)\n",
    "    \n",
    "    return df_reconstructed\n",
    "\n",
    "# reconstruct_from_tensor(cf_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_dataframe = reconstruct_from_tensor(cf_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = reconstruct_from_tensor(train_ext_x.swapaxes(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ext_x.swapaxes(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df.drop(columns=['datetime']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[2 3 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_df_1_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_dataframe.columns = feature_names\n",
    "test_df.columns = feature_names\n",
    "train_data_normalized.columns = feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_drift_detector import DataDriftDetector\n",
    "detector = DataDriftDetector(df_prior = train_data_normalized, df_post = test_df)\n",
    "detector.calculate_drift()\n",
    "detector.plot_numeric_to_numeric(plot_numeric_columns=['Accelerometer1RMS', 'Accelerometer2RMS'])\n",
    "plt.savefig('driftdetector_grad_vae_skab.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = DataDriftDetector(df_prior = train_data_normalized, df_post = cf_dataframe)\n",
    "detector.calculate_drift()\n",
    "detector.plot_numeric_to_numeric(plot_numeric_columns=['Accelerometer1RMS', 'Accelerometer2RMS'])\n",
    "plt.savefig('driftdetector_grad_vae_skab_cf.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
